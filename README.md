# PDEasy â€‹(â€‹0â€‹.â€‹1â€‹.â€‹2)â€‹ :zap:

[![PyPI Version](https://img.shields.io/pypi/v/pdeasy)](https://pypi.org/project/pdeasy/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

**PDEasy: Lightweight PINN & Operator PDE Solver for Research, Balancing Abstraction and Flexibility for Algorithm Innovation.**

> **Note:** ç›®å‰, å…³äº PINN (Physics-Informed Neural Networks) çš„ Python åº“å¤§éƒ½å°è£…ç¨‹åº¦è¾ƒé«˜, ä¸»è¦é¢å‘å·¥ç¨‹éƒ¨ç½²æˆ–æ–°æ‰‹å…¥é—¨. ç„¶è€Œ, å¯¹äº PINN ç›¸å…³ç§‘ç ”å·¥ä½œè€…æ¥è¯´, é€šè¿‡è¾ƒé«˜å°è£…çš„ä»£ç å»å®ç°è‡ªå·±çš„ idea æ˜¯éå¸¸å›°éš¾çš„. å› æ­¤, æˆ‘ä»¬å¸Œæœ›å†™ä¸€å¥—é¢å‘ç§‘ç ”å·¥ä½œè€…çš„ PINN-PDE æ±‚è§£åº“, å¹³è¡¡å°è£…ç¨‹åº¦ä¸æ‰©å±•æ€§, ä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿå¿«é€Ÿå®ç°æ–°çš„ idea, åŠ é€Ÿç®—æ³•åˆ›æ–°.

> **Log:**
>
> - 0.1.0ï¼Œå®ç°äº† PINN æ±‚è§£æ­£åé—®é¢˜çš„æ¡†æ¶ï¼Œæ”¯æŒå¤šè¾“å…¥è¾“å‡ºã€ä¾¿æ·æ±‚å¯¼ç­‰.
> - 0.1.1ï¼Œå®ç°äº† DeepONet æ±‚è§£ 1D ç®—ä¾‹ï¼Œå°† `pinn` é‡æ„ä¸º `framework`ï¼Œå…¼å®¹ç®—å­å­¦ä¹ æ¡†æ¶.
> - 0.1.2ï¼Œå®ç°äº† Physics-informed DeepONet æ±‚è§£ 1D ç®—ä¾‹ï¼Œå¢åŠ äº†é«˜é¢‘é—®é¢˜çš„ç®—ä¾‹.

## :rocket: Reference

> 1. ...
> 2. ...

## ğŸ”‘ Key Features

### 1. PINN æ±‚è§£æµç¨‹åŒ–

- **PINN æ±‚è§£æµç¨‹**è§„èŒƒä¸º: å®šä¹‰è¶…å‚æ•°, å®šä¹‰æ•°æ®é›†, å®šä¹‰ç½‘ç»œæ¨¡å‹, å®šä¹‰ PINN æ¨¡å‹, è®­ç»ƒæ¨¡å‹, è¯„ä¼°ä¸å¯è§†åŒ–.

- å…¶ä¸­, å„ç§**ç½‘ç»œ**æ¨¡å‹, **PINN æ­£åé—®é¢˜**æ¨¡å‹, å¯è§†åŒ–æ¨¡å—ç­‰éƒ½å®ç°äº†å°è£…, å¹¶æä¾›äº†æ‰©å±•æ¥å£.
- å°¤å…¶æ˜¯å¯¹äº PINN ç‰¹æœ‰çš„å¯¹è¾“å…¥åæ ‡**æ±‚åå¯¼**, ä¹Ÿå®ç°äº†ç®€åŒ–.

### 2. å¯ä»¥çµæ´»æ‰©å±•è‡ªå·±çš„ idea

- æ¡†æ¶å†…çš„æ•°æ®, ä¾‹å¦‚**é‡‡æ ·ç‚¹**å’Œ **loss** ä¿¡æ¯, éƒ½**ä»¥ dict çš„å½¢å¼æµåŠ¨**, ç”¨æˆ·å¯ä»¥è½»æ¾åœ°è¯»å–æˆ–åŠ å…¥ä¿¡æ¯, å¹¶èåˆé‡‡æ ·å’Œæƒé‡ç­‰ç®—æ³•.
- æœªå°è£…è®­ç»ƒæ¨¡å—, ä½¿ç”¨æˆ·æ›´å®¹æ˜“ä¿®æ”¹è®­ç»ƒè¿‡ç¨‹.
- PINN æ¨¡å‹æä¾›äº†è‰¯å¥½çš„æ‰©å±•æ¥å£, å¯ä»¥èåˆå„ç§ç½‘ç»œ, æˆ–å¢åŠ å„ç§è®¡ç®—æ–¹å¼.

### 3. å…¨é¢çš„è®­ç»ƒä¿¡æ¯ç›‘æ§

- è®­ç»ƒè¿‡ç¨‹ä¸­çš„ **loss** å’Œ **error**, éƒ½å¯ä»¥é€šè¿‡å°è£…æ¨¡å—å¿«é€Ÿè®¡ç®—, å¹¶å­˜å‚¨åˆ° **logger** ä¸­.
- å¯è§†åŒ–æ¨¡å—å¯ä»¥ç›´æ¥é€šè¿‡ logger ç»˜å›¾, å±•ç¤ºè®­ç»ƒè¿‡ç¨‹çš„å„é¡¹ loss å’Œ error çš„å˜åŒ–.

> **Note:** PDEasy åŸºäº PyTorch, NumPy, Matplotlib ç­‰ä¸»æµ Python packages.

## :package: Installation

ç›®å‰ä»…æ”¯æŒä¸‹è½½å‹ç¼©åŒ…ä½¿ç”¨.

## :hourglass_flowing_sand: Quick Start
è¿™é‡Œæˆ‘ä»¬ä»¥ Burgers æ–¹ç¨‹æ­£é—®é¢˜ä¸ºä¾‹, ä»‹ç» PDEasy çš„ä½¿ç”¨æ–¹æ³•. å®Œæ•´ä»£ç è§ `./example/Burgers_Forward_1DT/Burgers_Forward_1DT.py`.

> **Note:** åœ¨ `example`æ–‡ä»¶å¤¹ä¸­, æˆ‘ä»¬å®ç°äº† 1D, 2D ç©ºé—´ (å’Œæ—¶é—´)çš„ç®—ä¾‹, åŒ…æ‹¬æ­£é—®é¢˜å’Œåé—®é¢˜, å…±æœ‰ 7 ä¸ª. å…¶ä¸­, ç»“åˆäº† MLP, ResNet, Fourier Feature Network, Multi-Head Network ç­‰å„ç§ç½‘ç»œç±»å‹, ä»¥åŠå±•ç¤ºäº†è¾¹ç•Œçº¦æŸ, å°ºåº¦æ”¾ç¼©, è‡ªé€‚åº” loss æƒé‡ç­‰ç®—æ³•çš„èåˆ, åç»­ä¼šå…¬å¼€æ›´å¤šçš„ç®—ä¾‹.

### 0. å¯¼å…¥åº“

```python
import sys
sys.path.append("../../")

from dataset import Dataset1DT
from framework import PINNForward
from network import MLP
from utils import *
from plotting import *
```

### 1. å®šä¹‰è¶…å‚æ•°

```python
DATA_DIR = './data'
FIGURE_DIR = './figure'
LOG_DIR = './log'
MODEL_DIR = './model'

DOMAIN = (-1, 1, 0, 1)  			# (x_min, x_max, t_min, t_max)
N_RES = 2000    					# å†…éƒ¨ç‚¹æ•°é‡
N_BCS = 200	    					# è¾¹ç•Œç‚¹æ•°é‡
N_ICS = 200	    					# åˆå§‹ç‚¹æ•°é‡
N_ITERS = 20000    					# ç½‘ç»œè®­ç»ƒè¿­ä»£æ¬¡æ•°
NN_LAYERS = [2] + [40]*4 + [1]		# ç½‘ç»œå±‚
```

### 2. å®šä¹‰æ•°æ®é›†

```python
class Dataset(Dataset1DT):
    def __init__(self, domain):
        super().__init__(domain)

    def custom_update(self, n_res=N_RES, n_bcs=N_BCS, n_ics=N_ICS):
        self.interior_random(n_res)    # åœ¨å†…éƒ¨éšæœºé‡‡æ · n_res ä¸ªç‚¹
        self.boundary_random(n_bcs)    # åœ¨è¾¹ç•Œéšæœºé‡‡æ · n_res ä¸ªç‚¹
        self.initial_random(n_ics)     # åœ¨åˆå§‹æ—¶åˆ»éšæœºé‡‡æ · n_res ä¸ªç‚¹
```

### 3. å®šä¹‰ PINN æ¨¡å‹

```python
class PINN(PINNForward):
    def __init__(self, network_solution, should_normalize=True):
        super().__init__(network_solution, should_normalize)

    def forward(self, data_dict):
        # è¯»å– data_dict çš„æ•°æ®
        X_res, X_bcs, X_ics = data_dict["X_res"], data_dict["X_bcs"], data_dict["X_ics"]

        # è®¡ç®— point-wise loss
        # ä¾¿äºåç»­å¼•å…¥æƒé‡ç­–ç•¥
        loss_dict = {}
        loss_dict['pw_loss_res'] = self.net_res(X_res) ** 2
        loss_dict['pw_loss_bcs'] = self.net_bcs(X_bcs) ** 2
        loss_dict['pw_loss_ics'] = self.net_ics(X_ics) ** 2

        return loss_dict
    
    def net_res(self, X):
        x, t = self.split_columns_and_requires_grad(X)			# å°†å¤šåˆ—çš„è¾“å…¥åˆ†åˆ«æå–å‡ºæ¥
        u = self.net_sol([x, t])								# è·å¾—è¾“å‡ºè§£

        u_x = self.grad(u, x, 1)								# æ±‚ u å¯¹ x çš„ 1 é˜¶å¯¼
        u_t = self.grad(u, t, 1)								# æ±‚ u å¯¹ t çš„ 1 é˜¶å¯¼
        u_xx = self.grad(u, x, 2)								# æ±‚ u å¯¹ x çš„ 2 é˜¶å¯¼
        res_pred = u_t + u * u_x - (0.01 / torch.pi) * u_xx		# æ„é€ æ–¹ç¨‹æ®‹å·®
        return res_pred
    
    def net_bcs(self, X):
        u = self.net_sol(X)										# è·å¾—è¾“å‡ºè§£
        bcs_pred = u - 0										# æ„é€ è¾¹ç•Œæ¡ä»¶æ®‹å·®
        return bcs_pred
    
    def net_ics(self, X):
        u = self.net_sol(X)										# è·å¾—è¾“å‡ºè§£
        ics_pred = u + torch.sin(torch.pi * X[:, [0]])			# æ„é€ åˆå§‹æ¡ä»¶æ®‹å·®
        return ics_pred
```

### 4. è®­ç»ƒæ¨¡å‹

#### 4.1 åˆå§‹åŒ–è®­ç»ƒå®ä¾‹

```python
dataset = Dataset(DOMAIN)		# ç”Ÿæˆæ•°æ®é›†å®ä¾‹

network = MLP(NN_LAYERS)		# ç”Ÿæˆç½‘ç»œå®ä¾‹
pinn = PINN(network)			# ç”Ÿæˆ PINN å®ä¾‹
pinn.X_mean, pinn.X_std = dataset.data_dict['X_mean'], dataset.data_dict['X_std']

optimizer = optim.Adam(pinn.parameters(), lr=0.001)

log_keys = ['iter', 'loss', 'loss_res', 'loss_bcs', 'loss_ics', 'error_u']
logger = Logger(LOG_DIR, log_keys, num_iters=N_ITERS, print_interval=100)

```

#### 4.2 è®­ç»ƒ

```python
best_loss = np.inf
for it in range(N_ITERS):
    pinn.zero_grad()                                        # æ¸…é™¤æ¢¯åº¦
    loss_dict = pinn(dataset.data_dict)                     # è®¡ç®— point-wise loss
    
    pw_loss_res = loss_dict["pw_loss_res"]                  # æå– point-wise loss
    pw_loss_bcs = loss_dict["pw_loss_bcs"]
    pw_loss_ics = loss_dict["pw_loss_ics"]
    
    loss_res = torch.mean(pw_loss_res)                      # è®¡ç®— loss
    loss_bcs = torch.mean(pw_loss_bcs)						# å¯ä»¥å¼•å…¥æƒé‡ç®—æ³•
    loss_ics = torch.mean(pw_loss_ics)
        
    loss = loss_res + loss_bcs + loss_ics
    
    loss.backward()                                         # åå‘ä¼ æ’­    
    optimizer.step()                                        # æ›´æ–°ç½‘ç»œå‚æ•°

    error_u, _ = relative_error_of_solution(pinn, ref_data=(X, u), num_sample=500)

    logger.record(                                          # ä¿å­˜è®­ç»ƒä¿¡æ¯
        iter=it,                                            # æ¯éš”ä¸€å®šæ¬¡æ•°è‡ªåŠ¨æ‰“å°
        loss=loss.item(),
        loss_res=loss_res.item(),
        loss_bcs=loss_bcs.item(),
        loss_ics=loss_ics.item(),
        error_u=error_u
    )
    
    if it % 100 == 0:
        dataset.update()
    
    if loss.item() < best_loss:                             # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        model_info = {
            'iter': it,
            'nn_state': pinn.state_dict(),
        }
        torch.save(model_info, os.path.join(MODEL_DIR, 'model.pth'))
        best_loss = loss.item()

logger.print_elapsed_time()
logger.save()
```

### 5. è¯„ä¼°ä¸å¯è§†åŒ–

#### 5.1 å¯¼å…¥è®­ç»ƒä¿¡æ¯ä»¥åŠæ¨¡å‹å‚æ•°

```python
logger.load()

model_info = torch.load(os.path.join(MODEL_DIR, 'model.pth'))
pinn.load_state_dict(model_info['nn_state'])
pinn.eval()
```

#### 5.2 å¯è§†åŒ– loss å’Œ error

```python
plot_loss_from_logger(logger, FIGURE_DIR, show=True)
plot_error_from_logger(logger, FIGURE_DIR, show=True)
```

#### 5.3 å¯è§†åŒ– solution

```python
error_u, u_pred = relative_error_of_solution(pinn, ref_data=(X, u))

plot_solution_from_data(
    FIGURE_DIR, 
    x_grid=xx.reshape(u_shape),
    y_grid=tt.reshape(u_shape),
    sol=u.reshape(u_shape),
    sol_pred=u_pred.reshape(u_shape),

    x_label='$x$',
    y_label='$t$',

    x_ticks=np.linspace(-1, 1, 5),
    y_ticks=np.linspace(0, 1, 5),
    
    title_left=r'Reference $u(x,t)$',
    title_middle=r'Predicted $u(x,t)$',
    title_right=r'Absolute error'
)
```

## :books: Documentation
TODO.

## :handshake: Contributing
æˆ‘ä»¬æ¬¢è¿æ›´å¤šå¼€å‘è€…åŠ å…¥, è¯·è”ç³»:

- é‚®ç®± guanyu191@163.com
- å¾®ä¿¡ guanyu191

> **Note:** PDEasy å‰èº«ç”±æ•°æ®è°·å›¢é˜Ÿçš„æ½˜å† å®‡å’Œå¾æ¢“é”Ÿåœ¨ 2023 å¹´ 1 æœˆæ ¹æ®å›¢é˜Ÿç§‘ç ”éœ€æ±‚å¼€å‘, å½“æ—¶ä¸»è¦ç”¨äº PINN æ±‚è§£åé—®é¢˜. åœ¨ 2025 å¹´ 2 æœˆ, æˆ‘ä»¬é‡æ–°æ”¹è¿›ä»£ç , é¢å‘ PINN é¢†åŸŸç§‘ç ”å·¥ä½œè€…, å¼€å‘äº† PDEasy åº“. å¾€åæˆ‘ä»¬ä¼šè¿›ä¸€æ­¥å®Œå–„, æ”¯æŒæ›´å¤šçš„ PDE æ­£åé—®é¢˜.

## :scroll: License
MIT License. See [LICENSE](LICENSE) for details.

## :star: Citation
If using PDEasy in research:
```bibtex
@software{PDEasy,
  author = {Guanyu Pan},
  title = {PDEasy: Lightweight PINN-PDE Solver for Research, Balancing Abstraction and Flexibility for Algorithm Innovation.},
  year = {2025},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/Guanyu191/PDEasy}},
}
```
